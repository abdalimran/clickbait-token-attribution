{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_train.csv\n",
    "# !wget https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_test.csv\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"webis_train.csv\", usecols=[\"postText\", \"truthClass\"])\n",
    "test = pd.read_csv(\"webis_test.csv\", usecols=[\"postText\", \"truthClass\"])\n",
    "\n",
    "train.rename(columns={\"postText\": \"text\", \"truthClass\": \"label\"}, inplace=True)\n",
    "test.rename(columns={\"postText\": \"text\", \"truthClass\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19538, 2), (18979, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(text     54\n",
       " label     0\n",
       " dtype: int64,\n",
       " text     66\n",
       " label     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum(), test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "test = test.dropna(subset=[\"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets, ClassLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f0d673a1494747b276ebbee930d743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/38397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = concatenate_datasets(\n",
    "    [\n",
    "        Dataset.from_pandas(train, split=\"train\"),\n",
    "        Dataset.from_pandas(test, split=\"test\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = dataset.cast_column(\"label\", ClassLabel(names=[\"no-clickbait\", \"clickbait\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 26877\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5760\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAMPLE_SIZE = 15000\n",
    "\n",
    "# dataset = dataset.shuffle(seed=SEED).select([i for i in list(range(SAMPLE_SIZE))])\n",
    "\n",
    "train_test = dataset.train_test_split(test_size=0.3, stratify_by_column=\"label\")\n",
    "eval_test = train_test[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "webis17 = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"eval\": eval_test[\"train\"],\n",
    "        \"test\": eval_test[\"test\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "webis17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de64a70dd14e299105c90c63149d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcff6a95c9540ea9107e005f5f42ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b97c36a5ccd449b9cf247fff79192a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/2xxd54y12nx5621lgg7h46bh0000gn/T/ipykernel_25239/3352579705.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "/opt/miniconda3/envs/deeplearning/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/deeplearning/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74164bab8e84947a0bc5d2da32f07c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6829, 'grad_norm': 3.5480451583862305, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6713, 'grad_norm': 1.394675374031067, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n",
      "{'loss': 0.6541, 'grad_norm': 0.9673712253570557, 'learning_rate': 3e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6163, 'grad_norm': 1.959397315979004, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 0.5723, 'grad_norm': 1.4053595066070557, 'learning_rate': 5e-06, 'epoch': 0.06}\n",
      "{'loss': 0.5345, 'grad_norm': 1.1729432344436646, 'learning_rate': 6e-06, 'epoch': 0.07}\n",
      "{'loss': 0.5034, 'grad_norm': 1.3886669874191284, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 0.4346, 'grad_norm': 1.6903536319732666, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 0.4129, 'grad_norm': 2.8180015087127686, 'learning_rate': 9e-06, 'epoch': 0.11}\n",
      "{'loss': 0.4121, 'grad_norm': 4.301993370056152, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3919, 'grad_norm': 4.436676502227783, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4091, 'grad_norm': 2.2142672538757324, 'learning_rate': 1.2e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4035, 'grad_norm': 4.600700855255127, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.15}\n",
      "{'loss': 0.3506, 'grad_norm': 5.397814750671387, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3651, 'grad_norm': 7.207907676696777, 'learning_rate': 1.5e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3774, 'grad_norm': 2.2101473808288574, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.19}\n",
      "{'loss': 0.308, 'grad_norm': 3.4643163681030273, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.2}\n",
      "{'loss': 0.4236, 'grad_norm': 5.205620765686035, 'learning_rate': 1.8e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3343, 'grad_norm': 3.088582754135132, 'learning_rate': 1.9e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4026, 'grad_norm': 6.776134014129639, 'learning_rate': 2e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3755, 'grad_norm': 1.700903296470642, 'learning_rate': 2.1e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3812, 'grad_norm': 4.190993309020996, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3668, 'grad_norm': 4.182559013366699, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3947, 'grad_norm': 4.4844465255737305, 'learning_rate': 2.4e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3381, 'grad_norm': 2.0963175296783447, 'learning_rate': 2.5e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4342, 'grad_norm': 3.3156962394714355, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3707, 'grad_norm': 2.649845600128174, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3563, 'grad_norm': 2.9101452827453613, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3692, 'grad_norm': 2.7841591835021973, 'learning_rate': 2.9e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3676, 'grad_norm': 5.134452819824219, 'learning_rate': 3e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3616, 'grad_norm': 4.668623447418213, 'learning_rate': 3.1e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3303, 'grad_norm': 2.3991782665252686, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3353, 'grad_norm': 3.146974563598633, 'learning_rate': 3.3e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4023, 'grad_norm': 2.329540491104126, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.4}\n",
      "{'loss': 0.364, 'grad_norm': 2.1763176918029785, 'learning_rate': 3.5e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2965, 'grad_norm': 3.190803289413452, 'learning_rate': 3.6e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3277, 'grad_norm': 3.259488344192505, 'learning_rate': 3.7e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3292, 'grad_norm': 2.8424670696258545, 'learning_rate': 3.8e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3115, 'grad_norm': 1.4394373893737793, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.46}\n",
      "{'loss': 0.302, 'grad_norm': 2.3312642574310303, 'learning_rate': 4e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3232, 'grad_norm': 2.921355962753296, 'learning_rate': 4.1e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3644, 'grad_norm': 3.0305466651916504, 'learning_rate': 4.2e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3688, 'grad_norm': 1.7974423170089722, 'learning_rate': 4.3e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3037, 'grad_norm': 4.2448320388793945, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3915, 'grad_norm': 2.8925538063049316, 'learning_rate': 4.5e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3625, 'grad_norm': 1.5890274047851562, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3215, 'grad_norm': 2.414137363433838, 'learning_rate': 4.7e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3029, 'grad_norm': 1.4976290464401245, 'learning_rate': 4.8e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2788, 'grad_norm': 2.0781919956207275, 'learning_rate': 4.9e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3447, 'grad_norm': 3.362035036087036, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3469, 'grad_norm': 1.8956660032272339, 'learning_rate': 4.975247524752475e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3404, 'grad_norm': 2.2616357803344727, 'learning_rate': 4.950495049504951e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4025, 'grad_norm': 2.974705696105957, 'learning_rate': 4.925742574257426e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3601, 'grad_norm': 3.1498987674713135, 'learning_rate': 4.9009900990099014e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3476, 'grad_norm': 3.3366854190826416, 'learning_rate': 4.8762376237623764e-05, 'epoch': 0.65}\n",
      "{'loss': 0.298, 'grad_norm': 2.703106641769409, 'learning_rate': 4.851485148514851e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3551, 'grad_norm': 5.151459693908691, 'learning_rate': 4.826732673267327e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3059, 'grad_norm': 2.554151773452759, 'learning_rate': 4.801980198019802e-05, 'epoch': 0.69}\n",
      "{'loss': 0.363, 'grad_norm': 2.211087465286255, 'learning_rate': 4.7772277227722775e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2986, 'grad_norm': 2.284715414047241, 'learning_rate': 4.7524752475247525e-05, 'epoch': 0.71}\n",
      "{'loss': 0.384, 'grad_norm': 3.4195380210876465, 'learning_rate': 4.7277227722772274e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2992, 'grad_norm': 1.8367313146591187, 'learning_rate': 4.702970297029703e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3528, 'grad_norm': 1.715469241142273, 'learning_rate': 4.678217821782179e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3013, 'grad_norm': 0.9798669219017029, 'learning_rate': 4.653465346534654e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3412, 'grad_norm': 2.3710649013519287, 'learning_rate': 4.628712871287129e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3321, 'grad_norm': 2.076763153076172, 'learning_rate': 4.603960396039604e-05, 'epoch': 0.79}\n",
      "{'loss': 0.29, 'grad_norm': 3.026092529296875, 'learning_rate': 4.57920792079208e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3067, 'grad_norm': 2.179769515991211, 'learning_rate': 4.554455445544555e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3095, 'grad_norm': 1.6658506393432617, 'learning_rate': 4.52970297029703e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3529, 'grad_norm': 1.8908601999282837, 'learning_rate': 4.5049504950495054e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3275, 'grad_norm': 1.5493595600128174, 'learning_rate': 4.4801980198019804e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3447, 'grad_norm': 1.766571283340454, 'learning_rate': 4.455445544554456e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3734, 'grad_norm': 1.903250813484192, 'learning_rate': 4.430693069306931e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3613, 'grad_norm': 3.0662455558776855, 'learning_rate': 4.405940594059406e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2809, 'grad_norm': 1.9871141910552979, 'learning_rate': 4.3811881188118816e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2907, 'grad_norm': 2.112778902053833, 'learning_rate': 4.3564356435643565e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2727, 'grad_norm': 2.0390045642852783, 'learning_rate': 4.331683168316832e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2639, 'grad_norm': 1.9371775388717651, 'learning_rate': 4.306930693069307e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2675, 'grad_norm': 1.8010774850845337, 'learning_rate': 4.282178217821782e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3801, 'grad_norm': 1.5274362564086914, 'learning_rate': 4.257425742574258e-05, 'epoch': 0.95}\n",
      "{'loss': 0.2908, 'grad_norm': 1.814900517463684, 'learning_rate': 4.2326732673267326e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3571, 'grad_norm': 1.5242775678634644, 'learning_rate': 4.207920792079208e-05, 'epoch': 0.98}\n",
      "{'loss': 0.291, 'grad_norm': 1.2744555473327637, 'learning_rate': 4.183168316831683e-05, 'epoch': 0.99}\n",
      "{'loss': 0.3187, 'grad_norm': 2.393883228302002, 'learning_rate': 4.158415841584158e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa9b2a529e4d79ae670a66b2b79704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33016437292099, 'eval_accuracy': 0.85625, 'eval_runtime': 88.6895, 'eval_samples_per_second': 64.946, 'eval_steps_per_second': 1.015, 'epoch': 1.0}\n",
      "{'loss': 0.2314, 'grad_norm': 1.4596055746078491, 'learning_rate': 4.133663366336634e-05, 'epoch': 1.01}\n",
      "{'loss': 0.2658, 'grad_norm': 1.9573876857757568, 'learning_rate': 4.108910891089109e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3331, 'grad_norm': 2.959653377532959, 'learning_rate': 4.0841584158415844e-05, 'epoch': 1.04}\n",
      "{'loss': 0.2302, 'grad_norm': 2.3334872722625732, 'learning_rate': 4.05940594059406e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3311, 'grad_norm': 2.41355299949646, 'learning_rate': 4.034653465346535e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2308, 'grad_norm': 2.266474485397339, 'learning_rate': 4.0099009900990106e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2291, 'grad_norm': 6.090953826904297, 'learning_rate': 3.9851485148514856e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3083, 'grad_norm': 2.703024387359619, 'learning_rate': 3.9603960396039605e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2921, 'grad_norm': 2.016167163848877, 'learning_rate': 3.935643564356436e-05, 'epoch': 1.11}\n",
      "{'loss': 0.233, 'grad_norm': 1.479504108428955, 'learning_rate': 3.910891089108911e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2891, 'grad_norm': 2.405247926712036, 'learning_rate': 3.886138613861387e-05, 'epoch': 1.13}\n",
      "{'loss': 0.2237, 'grad_norm': 2.258867025375366, 'learning_rate': 3.861386138613862e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2764, 'grad_norm': 2.0549919605255127, 'learning_rate': 3.8366336633663367e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2173, 'grad_norm': 2.9467809200286865, 'learning_rate': 3.811881188118812e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2414, 'grad_norm': 2.4424357414245605, 'learning_rate': 3.787128712871287e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2892, 'grad_norm': 1.5056190490722656, 'learning_rate': 3.762376237623763e-05, 'epoch': 1.19}\n",
      "{'loss': 0.1992, 'grad_norm': 2.982645034790039, 'learning_rate': 3.737623762376238e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3066, 'grad_norm': 2.8769052028656006, 'learning_rate': 3.712871287128713e-05, 'epoch': 1.21}\n",
      "{'loss': 0.2722, 'grad_norm': 1.7085000276565552, 'learning_rate': 3.6881188118811884e-05, 'epoch': 1.23}\n",
      "{'loss': 0.2906, 'grad_norm': 2.949211597442627, 'learning_rate': 3.6633663366336634e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2656, 'grad_norm': 2.4210331439971924, 'learning_rate': 3.638613861386139e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2253, 'grad_norm': 4.210797309875488, 'learning_rate': 3.613861386138614e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2558, 'grad_norm': 3.3613526821136475, 'learning_rate': 3.589108910891089e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2767, 'grad_norm': 2.0558178424835205, 'learning_rate': 3.5643564356435645e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2487, 'grad_norm': 2.4164938926696777, 'learning_rate': 3.5396039603960395e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2594, 'grad_norm': 5.327923774719238, 'learning_rate': 3.514851485148515e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2484, 'grad_norm': 2.1004910469055176, 'learning_rate': 3.49009900990099e-05, 'epoch': 1.32}\n",
      "{'loss': 0.2617, 'grad_norm': 5.041275978088379, 'learning_rate': 3.465346534653465e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2204, 'grad_norm': 1.7032395601272583, 'learning_rate': 3.440594059405941e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2227, 'grad_norm': 3.9078822135925293, 'learning_rate': 3.415841584158416e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3014, 'grad_norm': 3.02882981300354, 'learning_rate': 3.391089108910891e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2713, 'grad_norm': 4.35841178894043, 'learning_rate': 3.366336633663367e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2742, 'grad_norm': 4.331200122833252, 'learning_rate': 3.341584158415842e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2601, 'grad_norm': 2.0548315048217773, 'learning_rate': 3.3168316831683175e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3363, 'grad_norm': 3.77276611328125, 'learning_rate': 3.2920792079207924e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2302, 'grad_norm': 4.207944869995117, 'learning_rate': 3.2673267326732674e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2782, 'grad_norm': 2.787996768951416, 'learning_rate': 3.242574257425743e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2349, 'grad_norm': 1.2950245141983032, 'learning_rate': 3.217821782178218e-05, 'epoch': 1.45}\n",
      "{'loss': 0.2259, 'grad_norm': 1.410923957824707, 'learning_rate': 3.1930693069306936e-05, 'epoch': 1.46}\n",
      "{'loss': 0.2167, 'grad_norm': 2.3514628410339355, 'learning_rate': 3.1683168316831686e-05, 'epoch': 1.48}\n",
      "{'loss': 0.2697, 'grad_norm': 3.9696216583251953, 'learning_rate': 3.1435643564356435e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2487, 'grad_norm': 3.565619707107544, 'learning_rate': 3.118811881188119e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2645, 'grad_norm': 2.331338405609131, 'learning_rate': 3.094059405940594e-05, 'epoch': 1.51}\n",
      "{'loss': 0.2695, 'grad_norm': 1.2676063776016235, 'learning_rate': 3.06930693069307e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2319, 'grad_norm': 3.282280206680298, 'learning_rate': 3.0445544554455447e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2713, 'grad_norm': 4.395236968994141, 'learning_rate': 3.01980198019802e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3344, 'grad_norm': 2.1481897830963135, 'learning_rate': 2.995049504950495e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2427, 'grad_norm': 2.635765314102173, 'learning_rate': 2.9702970297029702e-05, 'epoch': 1.57}\n",
      "{'loss': 0.1844, 'grad_norm': 1.7264652252197266, 'learning_rate': 2.9455445544554455e-05, 'epoch': 1.58}\n",
      "{'loss': 0.2192, 'grad_norm': 4.487038612365723, 'learning_rate': 2.9207920792079208e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2583, 'grad_norm': 1.6239877939224243, 'learning_rate': 2.896039603960396e-05, 'epoch': 1.61}\n",
      "{'loss': 0.2548, 'grad_norm': 5.318647861480713, 'learning_rate': 2.871287128712871e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3013, 'grad_norm': 2.4238264560699463, 'learning_rate': 2.8465346534653464e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2222, 'grad_norm': 2.213231086730957, 'learning_rate': 2.8217821782178216e-05, 'epoch': 1.64}\n",
      "{'loss': 0.2478, 'grad_norm': 4.961217880249023, 'learning_rate': 2.7970297029702973e-05, 'epoch': 1.65}\n",
      "{'loss': 0.2825, 'grad_norm': 2.801023483276367, 'learning_rate': 2.7722772277227726e-05, 'epoch': 1.67}\n",
      "{'loss': 0.2289, 'grad_norm': 1.8112627267837524, 'learning_rate': 2.747524752475248e-05, 'epoch': 1.68}\n",
      "{'loss': 0.2189, 'grad_norm': 4.422991752624512, 'learning_rate': 2.722772277227723e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2746, 'grad_norm': 1.7580530643463135, 'learning_rate': 2.6980198019801985e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2893, 'grad_norm': 2.8740596771240234, 'learning_rate': 2.6732673267326734e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2231, 'grad_norm': 3.6404144763946533, 'learning_rate': 2.6485148514851487e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2622, 'grad_norm': 2.7570669651031494, 'learning_rate': 2.623762376237624e-05, 'epoch': 1.74}\n",
      "{'loss': 0.2958, 'grad_norm': 2.0683281421661377, 'learning_rate': 2.5990099009900993e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2318, 'grad_norm': 3.3903732299804688, 'learning_rate': 2.5742574257425746e-05, 'epoch': 1.76}\n",
      "{'loss': 0.2339, 'grad_norm': 4.398138046264648, 'learning_rate': 2.5495049504950495e-05, 'epoch': 1.77}\n",
      "{'loss': 0.2286, 'grad_norm': 3.11541748046875, 'learning_rate': 2.5247524752475248e-05, 'epoch': 1.79}\n",
      "{'loss': 0.2539, 'grad_norm': 1.9553749561309814, 'learning_rate': 2.5e-05, 'epoch': 1.8}\n",
      "{'loss': 0.1932, 'grad_norm': 0.8151450753211975, 'learning_rate': 2.4752475247524754e-05, 'epoch': 1.81}\n",
      "{'loss': 0.2325, 'grad_norm': 3.3592140674591064, 'learning_rate': 2.4504950495049507e-05, 'epoch': 1.82}\n",
      "{'loss': 0.2581, 'grad_norm': 2.257277011871338, 'learning_rate': 2.4257425742574257e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2413, 'grad_norm': 4.896945476531982, 'learning_rate': 2.400990099009901e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2251, 'grad_norm': 1.9794379472732544, 'learning_rate': 2.3762376237623762e-05, 'epoch': 1.86}\n",
      "{'loss': 0.2857, 'grad_norm': 3.079981565475464, 'learning_rate': 2.3514851485148515e-05, 'epoch': 1.87}\n",
      "{'loss': 0.2925, 'grad_norm': 2.617161750793457, 'learning_rate': 2.326732673267327e-05, 'epoch': 1.88}\n",
      "{'loss': 0.2571, 'grad_norm': 3.0461127758026123, 'learning_rate': 2.301980198019802e-05, 'epoch': 1.89}\n",
      "{'loss': 0.244, 'grad_norm': 2.1552045345306396, 'learning_rate': 2.2772277227722774e-05, 'epoch': 1.9}\n",
      "{'loss': 0.2397, 'grad_norm': 1.8899422883987427, 'learning_rate': 2.2524752475247527e-05, 'epoch': 1.92}\n",
      "{'loss': 0.2432, 'grad_norm': 4.008581161499023, 'learning_rate': 2.227722772277228e-05, 'epoch': 1.93}\n",
      "{'loss': 0.275, 'grad_norm': 2.825641632080078, 'learning_rate': 2.202970297029703e-05, 'epoch': 1.94}\n",
      "{'loss': 0.275, 'grad_norm': 3.612758159637451, 'learning_rate': 2.1782178217821783e-05, 'epoch': 1.95}\n",
      "{'loss': 0.229, 'grad_norm': 2.9279510974884033, 'learning_rate': 2.1534653465346535e-05, 'epoch': 1.96}\n",
      "{'loss': 0.2514, 'grad_norm': 1.3950340747833252, 'learning_rate': 2.128712871287129e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2464, 'grad_norm': 1.1058939695358276, 'learning_rate': 2.103960396039604e-05, 'epoch': 1.99}\n",
      "{'loss': 0.2413, 'grad_norm': 2.5209012031555176, 'learning_rate': 2.079207920792079e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c41919509d47789784fb4dff4c9aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3441505432128906, 'eval_accuracy': 0.8642361111111111, 'eval_runtime': 100.6562, 'eval_samples_per_second': 57.224, 'eval_steps_per_second': 0.894, 'epoch': 2.0}\n",
      "{'loss': 0.1586, 'grad_norm': 2.922562599182129, 'learning_rate': 2.0544554455445544e-05, 'epoch': 2.01}\n",
      "{'loss': 0.122, 'grad_norm': 1.0166641473770142, 'learning_rate': 2.02970297029703e-05, 'epoch': 2.02}\n",
      "{'loss': 0.1813, 'grad_norm': 3.7492949962615967, 'learning_rate': 2.0049504950495053e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2032, 'grad_norm': 2.631622314453125, 'learning_rate': 1.9801980198019803e-05, 'epoch': 2.05}\n",
      "{'loss': 0.1812, 'grad_norm': 1.7663460969924927, 'learning_rate': 1.9554455445544556e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1406, 'grad_norm': 2.9212446212768555, 'learning_rate': 1.930693069306931e-05, 'epoch': 2.07}\n",
      "{'loss': 0.095, 'grad_norm': 0.839775562286377, 'learning_rate': 1.905940594059406e-05, 'epoch': 2.08}\n",
      "{'loss': 0.1857, 'grad_norm': 4.174498081207275, 'learning_rate': 1.8811881188118814e-05, 'epoch': 2.1}\n",
      "{'loss': 0.1732, 'grad_norm': 4.595023155212402, 'learning_rate': 1.8564356435643564e-05, 'epoch': 2.11}\n",
      "{'loss': 0.1704, 'grad_norm': 3.979828357696533, 'learning_rate': 1.8316831683168317e-05, 'epoch': 2.12}\n",
      "{'loss': 0.168, 'grad_norm': 4.890501976013184, 'learning_rate': 1.806930693069307e-05, 'epoch': 2.13}\n",
      "{'loss': 0.1373, 'grad_norm': 1.5472362041473389, 'learning_rate': 1.7821782178217823e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1399, 'grad_norm': 4.447357177734375, 'learning_rate': 1.7574257425742576e-05, 'epoch': 2.15}\n",
      "{'loss': 0.1704, 'grad_norm': 2.7076449394226074, 'learning_rate': 1.7326732673267325e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1561, 'grad_norm': 3.006490468978882, 'learning_rate': 1.707920792079208e-05, 'epoch': 2.18}\n",
      "{'loss': 0.18, 'grad_norm': 1.9211972951889038, 'learning_rate': 1.6831683168316834e-05, 'epoch': 2.19}\n",
      "{'loss': 0.1022, 'grad_norm': 4.314216136932373, 'learning_rate': 1.6584158415841587e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1037, 'grad_norm': 1.3573580980300903, 'learning_rate': 1.6336633663366337e-05, 'epoch': 2.21}\n",
      "{'loss': 0.1401, 'grad_norm': 2.644185781478882, 'learning_rate': 1.608910891089109e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1167, 'grad_norm': 0.5576093792915344, 'learning_rate': 1.5841584158415843e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1346, 'grad_norm': 4.6694159507751465, 'learning_rate': 1.5594059405940596e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1451, 'grad_norm': 2.9998483657836914, 'learning_rate': 1.534653465346535e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1033, 'grad_norm': 5.8960442543029785, 'learning_rate': 1.50990099009901e-05, 'epoch': 2.27}\n",
      "{'loss': 0.1732, 'grad_norm': 5.938567638397217, 'learning_rate': 1.4851485148514851e-05, 'epoch': 2.29}\n",
      "{'loss': 0.165, 'grad_norm': 3.0187268257141113, 'learning_rate': 1.4603960396039604e-05, 'epoch': 2.3}\n",
      "{'loss': 0.1843, 'grad_norm': 1.8085216283798218, 'learning_rate': 1.4356435643564355e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1218, 'grad_norm': 2.6296353340148926, 'learning_rate': 1.4108910891089108e-05, 'epoch': 2.32}\n",
      "{'loss': 0.1795, 'grad_norm': 1.4329665899276733, 'learning_rate': 1.3861386138613863e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1346, 'grad_norm': 5.7247490882873535, 'learning_rate': 1.3613861386138616e-05, 'epoch': 2.35}\n",
      "{'loss': 0.1181, 'grad_norm': 4.598413944244385, 'learning_rate': 1.3366336633663367e-05, 'epoch': 2.36}\n",
      "{'loss': 0.1381, 'grad_norm': 3.7448487281799316, 'learning_rate': 1.311881188118812e-05, 'epoch': 2.37}\n",
      "{'loss': 0.1291, 'grad_norm': 2.6805419921875, 'learning_rate': 1.2871287128712873e-05, 'epoch': 2.38}\n",
      "{'loss': 0.187, 'grad_norm': 4.347357273101807, 'learning_rate': 1.2623762376237624e-05, 'epoch': 2.39}\n",
      "{'loss': 0.1483, 'grad_norm': 2.310270071029663, 'learning_rate': 1.2376237623762377e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1747, 'grad_norm': 5.6801066398620605, 'learning_rate': 1.2128712871287128e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1064, 'grad_norm': 2.650747776031494, 'learning_rate': 1.1881188118811881e-05, 'epoch': 2.43}\n",
      "{'loss': 0.1286, 'grad_norm': 2.8128068447113037, 'learning_rate': 1.1633663366336634e-05, 'epoch': 2.44}\n",
      "{'loss': 0.1373, 'grad_norm': 2.7981514930725098, 'learning_rate': 1.1386138613861387e-05, 'epoch': 2.45}\n",
      "{'loss': 0.1264, 'grad_norm': 2.7931230068206787, 'learning_rate': 1.113861386138614e-05, 'epoch': 2.46}\n",
      "{'loss': 0.1627, 'grad_norm': 1.4297235012054443, 'learning_rate': 1.0891089108910891e-05, 'epoch': 2.48}\n",
      "{'loss': 0.1283, 'grad_norm': 2.5203983783721924, 'learning_rate': 1.0643564356435644e-05, 'epoch': 2.49}\n",
      "{'loss': 0.1179, 'grad_norm': 3.440645933151245, 'learning_rate': 1.0396039603960395e-05, 'epoch': 2.5}\n",
      "{'loss': 0.1911, 'grad_norm': 6.3709588050842285, 'learning_rate': 1.014851485148515e-05, 'epoch': 2.51}\n",
      "{'loss': 0.1228, 'grad_norm': 1.668585181236267, 'learning_rate': 9.900990099009901e-06, 'epoch': 2.52}\n",
      "{'loss': 0.1187, 'grad_norm': 4.1499552726745605, 'learning_rate': 9.653465346534654e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1098, 'grad_norm': 4.233168601989746, 'learning_rate': 9.405940594059407e-06, 'epoch': 2.55}\n",
      "{'loss': 0.1292, 'grad_norm': 3.145198345184326, 'learning_rate': 9.158415841584158e-06, 'epoch': 2.56}\n",
      "{'loss': 0.1126, 'grad_norm': 3.4833409786224365, 'learning_rate': 8.910891089108911e-06, 'epoch': 2.57}\n",
      "{'loss': 0.1541, 'grad_norm': 3.153385877609253, 'learning_rate': 8.663366336633663e-06, 'epoch': 2.58}\n",
      "{'loss': 0.1473, 'grad_norm': 3.9544544219970703, 'learning_rate': 8.415841584158417e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0963, 'grad_norm': 0.5501638054847717, 'learning_rate': 8.168316831683168e-06, 'epoch': 2.61}\n",
      "{'loss': 0.142, 'grad_norm': 4.847021579742432, 'learning_rate': 7.920792079207921e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1402, 'grad_norm': 4.785977363586426, 'learning_rate': 7.673267326732674e-06, 'epoch': 2.63}\n",
      "{'loss': 0.1856, 'grad_norm': 3.6526079177856445, 'learning_rate': 7.4257425742574256e-06, 'epoch': 2.64}\n",
      "{'loss': 0.1245, 'grad_norm': 3.5429494380950928, 'learning_rate': 7.178217821782178e-06, 'epoch': 2.65}\n",
      "{'loss': 0.1156, 'grad_norm': 6.0265021324157715, 'learning_rate': 6.9306930693069314e-06, 'epoch': 2.67}\n",
      "{'loss': 0.1457, 'grad_norm': 8.554455757141113, 'learning_rate': 6.6831683168316835e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0786, 'grad_norm': 3.5903639793395996, 'learning_rate': 6.4356435643564364e-06, 'epoch': 2.69}\n",
      "{'loss': 0.1545, 'grad_norm': 6.065860271453857, 'learning_rate': 6.1881188118811885e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1275, 'grad_norm': 4.594059467315674, 'learning_rate': 5.940594059405941e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1962, 'grad_norm': 1.1313145160675049, 'learning_rate': 5.6930693069306936e-06, 'epoch': 2.73}\n",
      "{'loss': 0.1388, 'grad_norm': 4.096596717834473, 'learning_rate': 5.445544554455446e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1342, 'grad_norm': 2.378535747528076, 'learning_rate': 5.198019801980198e-06, 'epoch': 2.75}\n",
      "{'loss': 0.089, 'grad_norm': 7.167601108551025, 'learning_rate': 4.950495049504951e-06, 'epoch': 2.76}\n",
      "{'loss': 0.1032, 'grad_norm': 7.881506443023682, 'learning_rate': 4.702970297029704e-06, 'epoch': 2.77}\n",
      "{'loss': 0.2373, 'grad_norm': 1.3999515771865845, 'learning_rate': 4.455445544554456e-06, 'epoch': 2.79}\n",
      "{'loss': 0.1141, 'grad_norm': 4.698871612548828, 'learning_rate': 4.207920792079209e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0874, 'grad_norm': 2.227412223815918, 'learning_rate': 3.960396039603961e-06, 'epoch': 2.81}\n",
      "{'loss': 0.1364, 'grad_norm': 5.91155481338501, 'learning_rate': 3.7128712871287128e-06, 'epoch': 2.82}\n",
      "{'loss': 0.1276, 'grad_norm': 6.0093770027160645, 'learning_rate': 3.4653465346534657e-06, 'epoch': 2.83}\n",
      "{'loss': 0.1025, 'grad_norm': 0.5739089250564575, 'learning_rate': 3.2178217821782182e-06, 'epoch': 2.85}\n",
      "{'loss': 0.1663, 'grad_norm': 4.885580062866211, 'learning_rate': 2.9702970297029703e-06, 'epoch': 2.86}\n",
      "{'loss': 0.1696, 'grad_norm': 3.650543212890625, 'learning_rate': 2.722772277227723e-06, 'epoch': 2.87}\n",
      "{'loss': 0.1107, 'grad_norm': 5.589005947113037, 'learning_rate': 2.4752475247524753e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1815, 'grad_norm': 4.624979019165039, 'learning_rate': 2.227722772277228e-06, 'epoch': 2.89}\n",
      "{'loss': 0.0936, 'grad_norm': 0.4392009973526001, 'learning_rate': 1.9801980198019803e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1611, 'grad_norm': 9.341824531555176, 'learning_rate': 1.7326732673267329e-06, 'epoch': 2.92}\n",
      "{'loss': 0.1286, 'grad_norm': 5.2597856521606445, 'learning_rate': 1.4851485148514852e-06, 'epoch': 2.93}\n",
      "{'loss': 0.1226, 'grad_norm': 4.18560791015625, 'learning_rate': 1.2376237623762377e-06, 'epoch': 2.94}\n",
      "{'loss': 0.1648, 'grad_norm': 3.5294530391693115, 'learning_rate': 9.900990099009902e-07, 'epoch': 2.95}\n",
      "{'loss': 0.1786, 'grad_norm': 6.998683452606201, 'learning_rate': 7.425742574257426e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1335, 'grad_norm': 4.057633876800537, 'learning_rate': 4.950495049504951e-07, 'epoch': 2.98}\n",
      "{'loss': 0.1817, 'grad_norm': 2.0357611179351807, 'learning_rate': 2.4752475247524754e-07, 'epoch': 2.99}\n",
      "{'loss': 0.1295, 'grad_norm': 5.718136787414551, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b0b023ef344f6886f1d3833b0c1669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4440048336982727, 'eval_accuracy': 0.8607638888888889, 'eval_runtime': 96.2392, 'eval_samples_per_second': 59.851, 'eval_steps_per_second': 0.935, 'epoch': 3.0}\n",
      "{'train_runtime': 4350.0188, 'train_samples_per_second': 18.536, 'train_steps_per_second': 0.579, 'train_loss': 0.2550725601968311, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe21f5b4ce4b08ab3f3be942f5237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.33016437292099, 'eval_accuracy': 0.85625, 'eval_runtime': 106.7996, 'eval_samples_per_second': 53.933, 'eval_steps_per_second': 0.843, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f453b9db82d147cbb359dc0fb0950293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'test_loss': 0.3227173388004303, 'test_accuracy': 0.8526041666666667, 'test_runtime': 109.7356, 'test_samples_per_second': 52.49, 'test_steps_per_second': 0.82}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_metric\n",
    "\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Define label mappings\n",
    "num_classes = len(webis17[\"train\"].features[\"label\"].names)\n",
    "id2label = {id: webis17[\"train\"].features[\"label\"].int2str(id) for id in range(num_classes)}\n",
    "label2id = {label: id for (id, label) in id2label.items()}\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_classes,\n",
    "    device_map=device,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=model.config.max_position_embeddings,\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_datasets = webis17.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(f\"{MODEL_NAME.split('/')[1]}_webis17_tuned\")\n",
    "tokenizer.save_pretrained(f\"{MODEL_NAME.split('/')[1]}_webis17_tuned\")\n",
    "\n",
    "# Test the model\n",
    "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(f\"Test results: {test_results.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With both the model and tokenizer initialized we are now able to get explanations on an example text.\n",
    "\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "cls_explainer = SequenceClassificationExplainer(model.to(\"cpu\"), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 0.0),\n",
       " ('shocking', 0.11747963820298502),\n",
       " ('revelation', -0.020785073184324515),\n",
       " (':', 0.3084187505542698),\n",
       " ('the', 0.43380586372039176),\n",
       " ('secret', 0.4525724881453869),\n",
       " ('ingredient', 0.29264621996251317),\n",
       " ('that', 0.11694752922367531),\n",
       " ('could', 0.07316515925753167),\n",
       " ('change', -0.32647736980122866),\n",
       " ('your', 0.3040690585780369),\n",
       " ('life', -0.17935635293153954),\n",
       " ('forever', -0.03716371129115278),\n",
       " ('!', 0.40045976313846154),\n",
       " ('[SEP]', 0.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_attributions = cls_explainer(\n",
    "    \"Shocking Revelation: The Secret Ingredient That Could Change Your Life Forever!\",\n",
    "    class_name=\"clickbait\",\n",
    ")\n",
    "word_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1), 'clickbait')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_explainer.predicted_class_index, cls_explainer.predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>clickbait</b></text></td><td><text style=\"padding-right:2em\"><b>clickbait (0.95)</b></text></td><td><text style=\"padding-right:2em\"><b>clickbait</b></text></td><td><text style=\"padding-right:2em\"><b>1.94</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shocking                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> revelation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> secret                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ingredient                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> could                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> change                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> forever                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_explainer.visualize(\"viz.html\", true_class=\"clickbait\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'no-clickbait', 1: 'clickbait'}, {'no-clickbait': 0, 'clickbait': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vocabulary with attribution score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset.to_pandas()\n",
    "corpus[\"label\"] = corpus.label.map({0: \"no-clickbait\", 1: \"clickbait\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9174/9174 [43:31<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "attribution_all = []\n",
    "\n",
    "# Get the total number of rows to be processed\n",
    "total_rows = len(corpus.query(\"label == 'clickbait'\"))\n",
    "\n",
    "# Wrap the iterable with tqdm for the progress bar\n",
    "for i, row in tqdm(corpus.query(\"label == 'clickbait'\").iterrows(), total=total_rows):\n",
    "    attribution_all.append(\n",
    "        cls_explainer(corpus.loc[i, \"text\"], class_name=corpus.loc[i, \"label\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "filename = \"vocabulary_clickbait_attribution.pkl\"\n",
    "\n",
    "# Open the file in write-binary mode ('wb')\n",
    "with open(filename, \"wb\") as file:\n",
    "    # Serialize and save the attribution_all object to the file\n",
    "    pickle.dump(attribution_all, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the file in read-binary mode ('rb')\n",
    "# with open(filename, \"rb\") as file:\n",
    "#     # Deserialize the object from the file\n",
    "#     vocabulary_attribution = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
