{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_train.csv\n",
    "# !wget https://ml-coding-test.s3.eu-west-1.amazonaws.com/webis_test.csv\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"webis_train.csv\", usecols=[\"postText\", \"truthClass\"])\n",
    "test = pd.read_csv(\"webis_test.csv\", usecols=[\"postText\", \"truthClass\"])\n",
    "\n",
    "train.rename(columns={\"postText\": \"text\", \"truthClass\": \"label\"}, inplace=True)\n",
    "test.rename(columns={\"postText\": \"text\", \"truthClass\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19538, 2), (18979, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(text     54\n",
       " label     0\n",
       " dtype: int64,\n",
       " text     66\n",
       " label     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum(), test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "test = test.dropna(subset=[\"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set a fixed seed value for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets, ClassLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da295f6e5a324403a192eca8f33681d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/38397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = concatenate_datasets(\n",
    "    [\n",
    "        Dataset.from_pandas(train, split=\"train\"),\n",
    "        Dataset.from_pandas(test, split=\"test\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = dataset.cast_column(\"label\", ClassLabel(names=[\"no-clickbait\", \"clickbait\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10500\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SIZE = 15000\n",
    "\n",
    "dataset = dataset.shuffle(seed=SEED).select([i for i in list(range(SAMPLE_SIZE))])\n",
    "\n",
    "train_test = dataset.train_test_split(test_size=0.3, stratify_by_column=\"label\")\n",
    "eval_test = train_test[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "webis17 = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"eval\": eval_test[\"train\"],\n",
    "        \"test\": eval_test[\"test\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "webis17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc4adca6cc45f79e6d4609877ee1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df2925a39f14ffe8e2bd03dcbf64021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfc118ac6f847848ad4d314b6450d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/2xxd54y12nx5621lgg7h46bh0000gn/T/ipykernel_1661/2124497837.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "/opt/miniconda3/envs/deeplearning/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/deeplearning/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3449f002043f58d82885d2bf8d5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6456, 'grad_norm': 1.4068024158477783, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.6321, 'grad_norm': 4.528217315673828, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6257, 'grad_norm': 0.7532750964164734, 'learning_rate': 3e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6052, 'grad_norm': 1.9847543239593506, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 0.5798, 'grad_norm': 1.6198363304138184, 'learning_rate': 5e-06, 'epoch': 0.15}\n",
      "{'loss': 0.5318, 'grad_norm': 4.512450695037842, 'learning_rate': 6e-06, 'epoch': 0.18}\n",
      "{'loss': 0.4967, 'grad_norm': 2.6624746322631836, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 0.4998, 'grad_norm': 2.8481016159057617, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 0.4336, 'grad_norm': 3.1879513263702393, 'learning_rate': 9e-06, 'epoch': 0.27}\n",
      "{'loss': 0.3728, 'grad_norm': 4.110686302185059, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4124, 'grad_norm': 5.555763244628906, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3807, 'grad_norm': 5.561615943908691, 'learning_rate': 1.2e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4073, 'grad_norm': 15.688480377197266, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3301, 'grad_norm': 4.712900161743164, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.43}\n",
      "{'loss': 0.374, 'grad_norm': 9.576543807983398, 'learning_rate': 1.5e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4502, 'grad_norm': 10.600465774536133, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3626, 'grad_norm': 5.118659019470215, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.52}\n",
      "{'loss': 0.299, 'grad_norm': 18.829574584960938, 'learning_rate': 1.8e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3256, 'grad_norm': 8.640666961669922, 'learning_rate': 1.9e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4195, 'grad_norm': 4.4134416580200195, 'learning_rate': 2e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3069, 'grad_norm': 9.892547607421875, 'learning_rate': 2.1e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3998, 'grad_norm': 10.725489616394043, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3602, 'grad_norm': 7.584234237670898, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2867, 'grad_norm': 6.320927619934082, 'learning_rate': 2.4e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3428, 'grad_norm': 7.527511119842529, 'learning_rate': 2.5e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3334, 'grad_norm': 5.425540447235107, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3477, 'grad_norm': 4.102044582366943, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.82}\n",
      "{'loss': 0.315, 'grad_norm': 6.459842681884766, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3268, 'grad_norm': 19.534154891967773, 'learning_rate': 2.9e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3016, 'grad_norm': 6.296432971954346, 'learning_rate': 3e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3394, 'grad_norm': 6.257689476013184, 'learning_rate': 3.1e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3719, 'grad_norm': 10.999401092529297, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a1bd5553734ce7a2ba5387df3bd57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33279648423194885, 'eval_accuracy': 0.8546666666666667, 'eval_runtime': 62.3947, 'eval_samples_per_second': 36.061, 'eval_steps_per_second': 0.577, 'epoch': 1.0}\n",
      "{'loss': 0.3801, 'grad_norm': 5.095461368560791, 'learning_rate': 3.3e-05, 'epoch': 1.0}\n",
      "{'loss': 0.3025, 'grad_norm': 6.850643157958984, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3266, 'grad_norm': 4.93298864364624, 'learning_rate': 3.5e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3388, 'grad_norm': 4.784635066986084, 'learning_rate': 3.6e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3033, 'grad_norm': 9.057267189025879, 'learning_rate': 3.7e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3279, 'grad_norm': 4.2189226150512695, 'learning_rate': 3.8e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2556, 'grad_norm': 9.13725471496582, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3282, 'grad_norm': 5.4304022789001465, 'learning_rate': 4e-05, 'epoch': 1.22}\n",
      "{'loss': 0.3053, 'grad_norm': 15.918543815612793, 'learning_rate': 4.1e-05, 'epoch': 1.25}\n",
      "{'loss': 0.303, 'grad_norm': 14.398245811462402, 'learning_rate': 4.2e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3349, 'grad_norm': 4.605914115905762, 'learning_rate': 4.3e-05, 'epoch': 1.31}\n",
      "{'loss': 0.246, 'grad_norm': 3.9327878952026367, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2905, 'grad_norm': 8.485918998718262, 'learning_rate': 4.5e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3074, 'grad_norm': 7.819408893585205, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3197, 'grad_norm': 6.164821147918701, 'learning_rate': 4.7e-05, 'epoch': 1.43}\n",
      "{'loss': 0.3586, 'grad_norm': 8.96356201171875, 'learning_rate': 4.8e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3216, 'grad_norm': 11.112160682678223, 'learning_rate': 4.9e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2968, 'grad_norm': 3.637479066848755, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3106, 'grad_norm': 7.670010089874268, 'learning_rate': 4.897330595482547e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2637, 'grad_norm': 5.428122043609619, 'learning_rate': 4.7946611909650925e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3189, 'grad_norm': 9.37517261505127, 'learning_rate': 4.691991786447639e-05, 'epoch': 1.61}\n",
      "{'loss': 0.2854, 'grad_norm': 7.01298713684082, 'learning_rate': 4.5893223819301853e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3012, 'grad_norm': 8.53171443939209, 'learning_rate': 4.486652977412731e-05, 'epoch': 1.67}\n",
      "{'loss': 0.3088, 'grad_norm': 5.371404647827148, 'learning_rate': 4.383983572895277e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2759, 'grad_norm': 4.629078388214111, 'learning_rate': 4.281314168377823e-05, 'epoch': 1.73}\n",
      "{'loss': 0.3492, 'grad_norm': 11.30841064453125, 'learning_rate': 4.17864476386037e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3401, 'grad_norm': 3.672577381134033, 'learning_rate': 4.075975359342916e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3179, 'grad_norm': 8.797113418579102, 'learning_rate': 3.973305954825462e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3027, 'grad_norm': 12.35723876953125, 'learning_rate': 3.8706365503080084e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3176, 'grad_norm': 7.119042873382568, 'learning_rate': 3.767967145790555e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3458, 'grad_norm': 3.562554359436035, 'learning_rate': 3.6652977412731007e-05, 'epoch': 1.91}\n",
      "{'loss': 0.3744, 'grad_norm': 7.069234371185303, 'learning_rate': 3.562628336755647e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3006, 'grad_norm': 6.137299060821533, 'learning_rate': 3.459958932238193e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b8486e4e074b7a9204dd27918d6a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32942432165145874, 'eval_accuracy': 0.8577777777777778, 'eval_runtime': 50.362, 'eval_samples_per_second': 44.677, 'eval_steps_per_second': 0.715, 'epoch': 2.0}\n",
      "{'loss': 0.3041, 'grad_norm': 4.700130462646484, 'learning_rate': 3.357289527720739e-05, 'epoch': 2.01}\n",
      "{'loss': 0.3335, 'grad_norm': 10.092000961303711, 'learning_rate': 3.254620123203286e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2398, 'grad_norm': 5.0191497802734375, 'learning_rate': 3.1519507186858315e-05, 'epoch': 2.07}\n",
      "{'loss': 0.223, 'grad_norm': 4.4642415046691895, 'learning_rate': 3.049281314168378e-05, 'epoch': 2.1}\n",
      "{'loss': 0.1256, 'grad_norm': 11.553142547607422, 'learning_rate': 2.9466119096509244e-05, 'epoch': 2.13}\n",
      "{'loss': 0.2267, 'grad_norm': 8.868629455566406, 'learning_rate': 2.8439425051334705e-05, 'epoch': 2.16}\n",
      "{'loss': 0.2146, 'grad_norm': 4.975587368011475, 'learning_rate': 2.7412731006160163e-05, 'epoch': 2.19}\n",
      "{'loss': 0.2349, 'grad_norm': 9.018712043762207, 'learning_rate': 2.6386036960985628e-05, 'epoch': 2.22}\n",
      "{'loss': 0.2609, 'grad_norm': 11.931863784790039, 'learning_rate': 2.5359342915811092e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2001, 'grad_norm': 4.043073654174805, 'learning_rate': 2.433264887063655e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1909, 'grad_norm': 4.0696611404418945, 'learning_rate': 2.3305954825462014e-05, 'epoch': 2.31}\n",
      "{'loss': 0.2053, 'grad_norm': 13.867682456970215, 'learning_rate': 2.2279260780287475e-05, 'epoch': 2.34}\n",
      "{'loss': 0.2055, 'grad_norm': 3.7993807792663574, 'learning_rate': 2.125256673511294e-05, 'epoch': 2.37}\n",
      "{'loss': 0.2265, 'grad_norm': 8.354172706604004, 'learning_rate': 2.02258726899384e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2304, 'grad_norm': 16.631765365600586, 'learning_rate': 1.919917864476386e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2115, 'grad_norm': 12.572168350219727, 'learning_rate': 1.8172484599589323e-05, 'epoch': 2.46}\n",
      "{'loss': 0.2204, 'grad_norm': 5.8415985107421875, 'learning_rate': 1.7145790554414784e-05, 'epoch': 2.49}\n",
      "{'loss': 0.2049, 'grad_norm': 5.162293434143066, 'learning_rate': 1.611909650924025e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1936, 'grad_norm': 5.857710838317871, 'learning_rate': 1.5092402464065708e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1583, 'grad_norm': 10.898957252502441, 'learning_rate': 1.406570841889117e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1788, 'grad_norm': 10.453450202941895, 'learning_rate': 1.3039014373716632e-05, 'epoch': 2.61}\n",
      "{'loss': 0.274, 'grad_norm': 19.08719253540039, 'learning_rate': 1.2012320328542096e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1601, 'grad_norm': 4.3337578773498535, 'learning_rate': 1.0985626283367557e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1098, 'grad_norm': 6.5239129066467285, 'learning_rate': 9.95893223819302e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2397, 'grad_norm': 7.786843299865723, 'learning_rate': 8.932238193018481e-06, 'epoch': 2.74}\n",
      "{'loss': 0.2338, 'grad_norm': 12.625899314880371, 'learning_rate': 7.905544147843944e-06, 'epoch': 2.77}\n",
      "{'loss': 0.1974, 'grad_norm': 6.753601551055908, 'learning_rate': 6.878850102669406e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2101, 'grad_norm': 4.227790832519531, 'learning_rate': 5.852156057494867e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2019, 'grad_norm': 2.3894827365875244, 'learning_rate': 4.825462012320329e-06, 'epoch': 2.86}\n",
      "{'loss': 0.152, 'grad_norm': 5.070320129394531, 'learning_rate': 3.7987679671457908e-06, 'epoch': 2.89}\n",
      "{'loss': 0.1715, 'grad_norm': 3.8609981536865234, 'learning_rate': 2.7720739219712527e-06, 'epoch': 2.92}\n",
      "{'loss': 0.1912, 'grad_norm': 7.391698837280273, 'learning_rate': 1.7453798767967144e-06, 'epoch': 2.95}\n",
      "{'loss': 0.1499, 'grad_norm': 5.986088275909424, 'learning_rate': 7.186858316221766e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb6dbdf0947428c8db2cc3820c722c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3719605505466461, 'eval_accuracy': 0.8644444444444445, 'eval_runtime': 49.5793, 'eval_samples_per_second': 45.382, 'eval_steps_per_second': 0.726, 'epoch': 3.0}\n",
      "{'train_runtime': 5458.21, 'train_samples_per_second': 5.771, 'train_steps_per_second': 0.181, 'train_loss': 0.3097732257939641, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43449be834194d5385453d2212cce176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.32942432165145874, 'eval_accuracy': 0.8577777777777778, 'eval_runtime': 50.2006, 'eval_samples_per_second': 44.82, 'eval_steps_per_second': 0.717, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fddf0cc6854b008388176b5d0bdf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'test_loss': 0.3352513015270233, 'test_accuracy': 0.8431111111111111, 'test_runtime': 53.9672, 'test_samples_per_second': 41.692, 'test_steps_per_second': 0.667}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_metric\n",
    "\n",
    "MODEL_NAME = \"FacebookAI/roberta-base\"\n",
    "\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Define label mappings\n",
    "num_classes = len(webis17[\"train\"].features[\"label\"].names)\n",
    "id2label = {id: webis17[\"train\"].features[\"label\"].int2str(id) for id in range(num_classes)}\n",
    "label2id = {label: id for (id, label) in id2label.items()}\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_classes,\n",
    "    device_map=device,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=model.config.max_position_embeddings,\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_datasets = webis17.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(f\"{MODEL_NAME.split('/')[1]}_webis17_tuned\")\n",
    "tokenizer.save_pretrained(f\"{MODEL_NAME.split('/')[1]}_webis17_tuned\")\n",
    "\n",
    "# Test the model\n",
    "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(f\"Test results: {test_results.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With both the model and tokenizer initialized we are now able to get explanations on an example text.\n",
    "\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "cls_explainer = SequenceClassificationExplainer(model.to(\"cpu\"), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 0.0),\n",
       " ('Sh', 0.07818216743942773),\n",
       " ('ocking', 0.7347983709536536),\n",
       " ('Revelation', 0.3717169262984062),\n",
       " (':', -0.20230018422187643),\n",
       " ('The', 0.030308820173817988),\n",
       " ('Secret', 0.3827598405571305),\n",
       " ('Ing', -0.03546143032901893),\n",
       " ('red', 0.12055172008267402),\n",
       " ('ient', -0.07413058733821046),\n",
       " ('That', 0.0014391813737729623),\n",
       " ('Could', 0.12493023668972683),\n",
       " ('Change', 0.1096041686176846),\n",
       " ('Your', 0.10885278207638402),\n",
       " ('Life', 0.059378179536186106),\n",
       " ('Forever', 0.04398845452252915),\n",
       " ('!', 0.24426642583253733),\n",
       " ('', 0.039399164901395334),\n",
       " ('</s>', 0.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_attributions = cls_explainer(\n",
    "    \"Shocking Revelation: The Secret Ingredient That Could Change Your Life Forever!\",\n",
    "    class_name=\"clickbait\",\n",
    ")\n",
    "word_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1), 'clickbait')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_explainer.predicted_class_index, cls_explainer.predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>clickbait</b></text></td><td><text style=\"padding-right:2em\"><b>clickbait (0.85)</b></text></td><td><text style=\"padding-right:2em\"><b>clickbait</b></text></td><td><text style=\"padding-right:2em\"><b>2.14</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Sh                    </font></mark><mark style=\"background-color: hsl(120, 75%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ocking                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Revelation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Secret                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> red                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ient                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> That                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Could                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Change                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Your                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Life                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Forever                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_explainer.visualize(\"viz.html\", true_class=\"clickbait\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'no-clickbait', 1: 'clickbait'}, {'no-clickbait': 0, 'clickbait': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
